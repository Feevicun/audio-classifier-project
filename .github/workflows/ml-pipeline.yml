name: ML Training and Deployment Pipeline

on:
  push:
    branches: [ main, master ]
    paths-ignore:
      - 'README.md'
      - 'docs/**'
      - '*.md'
  
  pull_request:
    branches: [ main, master ]
  
  workflow_dispatch:
    inputs:
      training_epochs:
        description: 'Number of training epochs'
        required: true
        default: '2'
        type: string
      download_data:
        description: 'Download dataset automatically'
        required: false
        default: true
        type: boolean

env:
  REGISTRY: ghcr.io
  IMAGE_NAME_TRAIN: ${{ github.repository }}-train
  IMAGE_NAME_INFERENCE: ${{ github.repository }}-inference
  MODEL_ARTIFACT_NAME: trained-model

jobs:
  # Job 1: ĞŸÑ–Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ¸Ñ… Ñ‚Ğ° Ñ‚Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ–
  train-model:
    name: Train ML Model
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      model-version: ${{ steps.version.outputs.model-version }}
      training-status: ${{ steps.train.outputs.training-status }}
      accuracy: ${{ steps.train.outputs.accuracy }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Setup Python for data download
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies for data handling
      run: |
        pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
    
    - name: Download SpeechCommands dataset
      if: github.event.inputs.download_data != 'false'
      run: |
        echo "ğŸ“¥ Downloading SpeechCommands dataset..."
        python -c "
        import torchaudio
        import os
        
        print('Downloading training data...')
        train_dataset = torchaudio.datasets.SPEECHCOMMANDS(
            root='./data', 
            download=True, 
            subset='training'
        )
        
        print('Downloading testing data...')
        test_dataset = torchaudio.datasets.SPEECHCOMMANDS(
            root='./data', 
            download=True, 
            subset='testing'
        )
        
        print('âœ… Dataset downloaded successfully!')
        print(f'Training samples: {len(train_dataset)}')
        print(f'Testing samples: {len(test_dataset)}')
        "
    
    - name: Verify data structure
      run: |
        echo "ğŸ“ Checking data structure..."
        if [ -d "data/SpeechCommands" ]; then
          echo "âœ… Found SpeechCommands data"
          find data/SpeechCommands -name "*.wav" | head -10 || echo "No WAV files found"
        else
          echo "âš ï¸ No SpeechCommands data found, will use synthetic data for testing"
        fi
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Generate model version
      id: version
      run: |
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        COMMIT_SHA_SHORT=${GITHUB_SHA:0:8}
        echo "model-version=v${TIMESTAMP}-${COMMIT_SHA_SHORT}" >> $GITHUB_OUTPUT
        echo "version=${TIMESTAMP}-${COMMIT_SHA_SHORT}" >> $GITHUB_OUTPUT
    
    - name: Build training image
      id: build-train
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./docker/Dockerfile.train
        tags: train-image:latest
        load: true
        outputs: type=docker,dest=/tmp/train-image.tar
    
    - name: Load training image
      run: |
        echo "ğŸ“¦ Loading training image..."
        docker load --input /tmp/train-image.tar
        docker images | grep train-image
    
    - name: Train model
      id: train
      run: |
        echo "ğŸš€ Starting model training..."
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ñ”Ğ¼Ğ¾ Ñ‚Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ· Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ·Ñƒ
        docker run --rm \
          -v $(pwd):/app \
          -e EPOCHS=${{ github.event.inputs.training_epochs || '2' }} \
          train-image:latest
        
        # ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ”Ğ¼Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸ Ñ‚Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ
        echo "ğŸ” Checking for model files..."
        ls -la | grep -E "model.pth|training.log" || echo "No model or log files found"
        
        if [ -f "model.pth" ]; then
          echo "âœ… Model trained successfully - model.pth found"
          echo "training-status=success" >> $GITHUB_OUTPUT
          
          # ĞÑ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ğ¼Ğ¾ accuracy Ğ· Ğ»Ğ¾Ğ³Ñ–Ğ²
          if [ -f "training.log" ]; then
            ACCURACY=$(grep "Accuracy:" training.log | tail -1 | grep -o '[0-9]*\.[0-9]*' | head -1 || echo "0")
            echo "accuracy=$ACCURACY" >> $GITHUB_OUTPUT
            echo "ğŸ“Š Final Accuracy: $ACCURACY%"
          else
            echo "accuracy=0" >> $GITHUB_OUTPUT
          fi
        else
          echo "âŒ Model training failed - no model file created"
          echo "training-status=failed" >> $GITHUB_OUTPUT
          echo "accuracy=0" >> $GITHUB_OUTPUT
          exit 1
        fi
    
    - name: Upload trained model and logs
      uses: actions/upload-artifact@v4
      with:
        name: ${{ env.MODEL_ARTIFACT_NAME }}
        path: |
          model.pth
          class_info.json
          training.log
        retention-days: 30
        if-no-files-found: error

  # Job 2: Ğ‘Ñ–Ğ»Ğ´ inference ÑĞµÑ€Ğ²ĞµÑ€Ğ°
  build-inference:
    name: Build Inference Server
    runs-on: ubuntu-latest
    needs: train-model
    if: needs.train-model.outputs.training-status == 'success'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download trained model
      uses: actions/download-artifact@v4
      with:
        name: ${{ env.MODEL_ARTIFACT_NAME }}
        path: ./
    
    - name: Verify model files
      run: |
        echo "ğŸ” Verifying model artifacts..."
        ls -la model.pth || echo "model.pth not found"
        ls -la class_info.json || echo "class_info.json not found"
        [ -f "model.pth" ] && echo "âœ… model.pth found" || echo "âŒ model.pth missing"
        [ -f "class_info.json" ] && echo "âœ… class_info.json found" || echo "âŒ class_info.json missing"
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build inference image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./docker/Dockerfile.inference
        tags: inference-image:latest
        load: true
        outputs: type=docker,dest=/tmp/inference-image.tar
    
    - name: Save inference image as artifact
      uses: actions/upload-artifact@v4
      with:
        name: inference-image
        path: /tmp/inference-image.tar
        retention-days: 7
        if-no-files-found: error

  # Job 3: Ğ¢ĞµÑÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ–
  test-model:
    name: Test Model Quality
    runs-on: ubuntu-latest
    needs: train-model
    if: needs.train-model.outputs.training-status == 'success'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download trained model
      uses: actions/download-artifact@v4
      with:
        name: ${{ env.MODEL_ARTIFACT_NAME }}
        path: ./
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-html
    
    - name: Run model tests
      run: |
        echo "ğŸ§ª Running model tests..."
        python -m pytest tests/ -v --html=test-report.html --self-contained-html
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      with:
        name: test-results
        path: |
          test-report.html
          training.log
        retention-days: 30
        if-no-files-found: warn

  # Job 4: Performance benchmarking
  benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    needs: [train-model, build-inference]
    if: needs.train-model.outputs.training-status == 'success'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download model
      uses: actions/download-artifact@v4
      with:
        name: ${{ env.MODEL_ARTIFACT_NAME }}
        path: ./
    
    - name: Build inference image locally
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./docker/Dockerfile.inference
        tags: inference-image:latest
        load: true
        outputs: type=docker,dest=/tmp/inference-image.tar
    
    - name: Load inference image
      run: |
        docker load --input /tmp/inference-image.tar
        docker images | grep inference-image
    
    - name: Install benchmark dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Run performance tests
      run: |
        echo "âš¡ Starting performance benchmark..."
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ñ”Ğ¼Ğ¾ ÑĞµÑ€Ğ²ĞµÑ€ Ñƒ Ñ„Ğ¾Ğ½Ñ–
        docker run -d --name inference-server -p 5000:5000 inference-image:latest
        
        # Ğ§ĞµĞºĞ°Ñ”Ğ¼Ğ¾ Ğ½Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ñ–ÑÑ‚ÑŒ ÑĞµÑ€Ğ²ĞµÑ€Ğ°
        echo "â³ Waiting for server to start..."
        for i in {1..30}; do
          if curl -s -f http://localhost:5000/health > /dev/null; then
            echo "âœ… Server is ready!"
            break
          fi
          sleep 2
        done
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ñ”Ğ¼Ğ¾ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€Ğº
        echo "ğŸ“Š Running benchmark..."
        python benchmark.py --url http://localhost:5000 --output benchmark-results.json --requests 3
        
        # Ğ—ÑƒĞ¿Ğ¸Ğ½ÑÑ”Ğ¼Ğ¾ ÑĞµÑ€Ğ²ĞµÑ€
        docker stop inference-server
        docker rm inference-server
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: benchmark-results.json
        retention-days: 30
        if-no-files-found: warn

  # Job 5: Generate Report
  report:
    name: Generate Pipeline Report
    runs-on: ubuntu-latest
    needs: [train-model, test-model, benchmark]
    if: always()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Generate Markdown report
      run: |
        cat > pipeline-report.md << EOF
        # ML Pipeline Report
        
        ## Execution Summary
        - **Pipeline ID**: ${{ github.run_id }}
        - **Trigger**: ${{ github.event_name }}
        - **Commit**: ${{ github.sha }}
        - **Model Version**: ${{ needs.train-model.outputs.model-version || 'N/A' }}
        - **Accuracy**: ${{ needs.train-model.outputs.accuracy || 'N/A' }}%
        
        ## Job Status
        - Training: ${{ needs.train-model.result }}
        - Testing: ${{ needs.test-model.result }}
        - Benchmark: ${{ needs.benchmark.result }}
        
        ## Next Steps
        1. Review test results
        2. Check benchmark metrics
        3. Deploy if all checks pass
        
        EOF
    
    - name: Upload pipeline report
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-report
        path: pipeline-report.md
        retention-days: 30